from openai import OpenAI
import streamlit as st
import pandas as pd

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

st.set_page_config(page_title="Paw patrol AI",
                   page_icon="ğŸ™")
st.title("ãƒ‘ã‚¦ãƒ‘ãƒˆAI")
st.subheader("ãƒ‘ã‚¦ãƒ‘ãƒˆã«ã¤ã„ã¦ä½•ã§ã‚‚èã„ã¦ã¿ã‚ˆã†ï¼")
character = st.radio("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼", ["ã‚±ãƒ³ãƒˆ", "ãƒã‚§ã‚¤ã‚¹"], horizontal = True)

#########################################
#user_input = st.text_area("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "Hello, Paw patrol!", height=200)
#voice = st.radio("voice", ["alloy", "echo", "fable", "onyx", "nova", "shimmer"], horizontal = True)

#if user_input:
#    try:
#        # éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡
#        response = client.audio.speech.create(
#            model="tts-1",
#            voice=voice,
#            input=user_input,
#        )
#        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
#        output_file = "output.mp3"
#        response.stream_to_file(output_file)
#        # ãƒ¦ãƒ¼ã‚¶ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›
#        st.audio(output_file, autoplay = True)
#    except Exception as e:
#        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
#else:
#    st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ãƒ¦ãƒ¼ã‚¶ãŒãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã€Enterã‚’æŠ¼ã—ãŸã‚‰å‡¦ç†ã‚’é–‹å§‹
#if st.button('éŸ³å£°åˆæˆ'):
#    if user_input:
#        try:
#            # éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡
#            response = client.audio.speech.create(
#                model="tts-1",
#                voice=voice,
#                input=user_input,
#            )
#            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
#            output_file = "output.mp3"
#            response.stream_to_file(output_file)
#            # ãƒ¦ãƒ¼ã‚¶ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›
#            st.audio(output_file)
#        except Exception as e:
#            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
#    else:
#        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

##############################################

#DEFAULT_TEXT = """Hello, Paw patrol!"""
#if "audio" not in st.session_state:
#    st.session_state["audio"] = None
#text = st.text_area("text", value = DEFAULT_TEXT, max_chars=4096, height=250)
#voice = st.radio("voice", ["alloy", "echo", "fable", "onyx", "nova", "shimmer"], horizontal = True)
#st.audio("data/cat-purr.mp3", format="audio/mpeg", loop=True)

#def text_to_speech(text, voice):
#    #speech_file_path = Path("audio.mp3")
#    speech_file_path = Path("data/audio.mp3")
#    response = client.audio.speech.create(
#      model="tts-1",
#      voice=voice,
#      input=text
#    )
#    response.stream_to_file(speech_file_path)

#with st.spinner("Generating your audio - this can take up to 30 seconds..."):
#    st.session_state["audio"] = text_to_speech(text, voice)
#    audio_file = open("data/audio.mp3", 'rb')
#    audio_bytes = audio_file.read()
#    st.audio(audio_bytes, format='audio/mpeg')

############################################################################
# èƒŒæ™¯ç”»åƒã®é¸æŠã¨streamlitã«ã‚ˆã‚‹è¡¨ç¤º
import base64

# ç”»åƒã®ãƒ‘ã‚¹
background_image = 'data/paw_figure1.png'

# ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
def get_image_base64(image_path):
    with open(image_path, 'rb') as img_file:
        b64_string = base64.b64encode(img_file.read()).decode('utf-8')
    return b64_string

# ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
base64_image = get_image_base64(background_image)

# ã‚«ã‚¹ã‚¿ãƒ CSSã‚’ä½¿ã£ã¦èƒŒæ™¯ç”»åƒã‚’è¨­å®š
page_bg_img = f'''
<style>
.stApp {{
background-image: url("data:image/png;base64,{base64_image}");
background-size: cover;
background-repeat: no-repeat;
background-attachment: fixed;
}}
</style>
'''

# ã‚«ã‚¹ã‚¿ãƒ CSSã‚’æŒ¿å…¥
st.markdown(page_bg_img, unsafe_allow_html=True)
############################################################################


# data
df = pd.read_csv('data/paw_data.csv')
data1 = df
#data1 = df["èª¬æ˜"]
#data1 = df["èª¬æ˜"][0:10]
data2 = data1.to_string()
#st.markdown(df.head())

# template
template = '''
ã‚ãªãŸã¯ã‚«ãƒŠãƒ€è£½ã®å­ä¾›ç”¨ã‚¢ãƒ‹ãƒ¡ã€Œãƒ‘ã‚¦ãƒ‘ãƒˆãƒ­ãƒ¼ãƒ«ã€ã«ã¤ã„ã¦ä½•ã§ã‚‚å¿œç­”ã™ã‚‹AIã§ã™ã€‚
æŒ‡å®šã•ã‚ŒãŸå½¹å‰²ãŒã‚ã‚Œã°ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã‚»ãƒªãƒ•ã«å¿œã˜ã¦ç­”ãˆã¦ã‚ã’ã¦ãã ã•ã„ã€‚
è³ªå•è€…ã¯åŸºæœ¬çš„ã«æœªå°±å­¦ã®å­ä¾›ãªã®ã§ã€ç°¡å˜ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
ç‰¹ã«ã€"""__MSG2__"""ã«ãªã‚Šãã£ã¦ãã ã•ã„ã€‚

### æ¡ä»¶
- å…¨ã¦ã®è³ªå•ã«å¯¾ã—ã¦ã€è¿”ç­”å†…å®¹ã«é–¢ã™ã‚‹ä»¥ä¸‹ã®ã€Œè³‡æ–™ã€ã‚’å‚ç…§ã—ãŸä¸Šã§ã€å½¹å‰²ã«ãªã‚Šãã£ã¦ç­”ãˆã¦ãã ã•ã„ã€‚
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®åå‰ã‚’å‘¼ã°ã‚ŒãŸã‚‰ã€ãã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã‚»ãƒªãƒ•ã‚’å¿ å®Ÿã«å†ç¾ã—ã¦ä¸‹ã•ã„ã€‚ãã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒè¨€ã„ãã†ãªã“ã¨ã‚’è¨€ã£ã¦ãã ã•ã„ã€‚
- ãƒ©ã‚¤ãƒ€ãƒ¼ã¯åˆ¥åã‚±ãƒ³ãƒˆã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

### è³‡æ–™
"""__MSG__"""
'''

template = template.replace('__MSG__', data2.replace('"', ''))
#template = template.replace('__MSG2__', character.replace('"', ''))

# OpenAIã®ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
if "openai_model" not in st.session_state:
    #st.session_state["openai_model"] = "gpt-3.5-turbo"
    st.session_state["openai_model"] = "gpt-4o-mini"

# ãƒãƒ£ãƒƒãƒˆã®å±¥æ­´ messages ã‚’åˆæœŸåŒ–ï¼ˆä¸€ã¤ä¸€ã¤ã® messages ã¯ {role, content} ã®å½¢å¼ï¼‰
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages = [{'role': 'system', 'content': template}]


# ãã‚Œã¾ã§ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¨ã¦è¡¨ç¤ºã—ãŸã¾ã¾ã«ã™ã‚‹ï¼ˆã“ã®loopãŒãªã„ã¨ã€åŒã˜å ´æ‰€ã‚’æ›´æ–°ã—ãªãŒã‚‰ä¼šè©±ãŒç¶šãï¼‰
for message in st.session_state.messages[1:]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"]) # è¡¨ç¤ºã™ã‚‹ï¼ˆä¸€ç¬ã§ã™ã¹ã¦æ›¸ãä¸‹ã™ï¼‰


# å…¥åŠ›ã•ã‚ŒãŸã‚‰ã€å†…å®¹ã‚’promptã«æ ¼ç´(å…¥åŠ›ã¾ã§ã¯å¾…æ©Ÿ)
if prompt := st.chat_input("è³ªå•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"):
    # messagesã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚¤ã‚³ãƒ³ã§ã€promptã‚’ãã®ã¾ã¾è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIã®ã‚¢ã‚¤ã‚³ãƒ³ã§
    with st.chat_message("assistant"):
        # ChatGPTã®è¿”ç­”ã‚’streamã«æ ¼ç´
        stream = client.chat.completions.create(
            model = st.session_state["openai_model"],
            # ä¼šè©±å±¥æ­´ã‚’ã™ã¹ã¦å‚ç…§ã—ã¦æ¸¡ã™
            messages = [
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream = True,
            temperature = 0.5,
        )
        # AIã®è¿”ç­”ã‚’æµã‚Œã‚‹ã‚ˆã†ã«å‡ºåŠ›
        response = st.write_stream(stream)

        user_input = response
        if user_input:
            try:
                # éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã®é€ä¿¡
                response = client.audio.speech.create(
                    model="tts-1",
                    voice=voice,
                    input=user_input,
                )
                # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                output_file = "output.mp3"
                response.stream_to_file(output_file)
                # ãƒ¦ãƒ¼ã‚¶ã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›
                st.audio(output_file, autoplay = True)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        else:
            st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    
    # messagesã«AIã®è¿”ç­”ã‚’æ ¼ç´
    st.session_state.messages.append({"role": "assistant", "content": response})
    #ã€€ã“ã“ã§ä¸€æ—¦çµ‚ã‚ã‚Šã€å…¥åŠ›å¾…æ©Ÿã¨ãªã‚‹

